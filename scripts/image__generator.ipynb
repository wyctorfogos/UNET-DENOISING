{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNET model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet():\n",
    "\tdef __init__(self):\n",
    "\t\tself.input_dimension=(32,32,3)\n",
    "\t\t\n",
    "\tdef double_conv_block(self,x, n_filters):\n",
    "\t\t# Conv2D then ReLU activation\n",
    "\t\tx = layers.Conv2D(n_filters, 3, strides=(1, 1), padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "\t\t# Conv2D then ReLU activation\n",
    "\t\tx = layers.Conv2D(n_filters, 3, strides=(1, 1), padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef downsample_block(self,x, n_filters):\n",
    "\t\tf = self.double_conv_block(x, n_filters)\n",
    "\t\tp = layers.MaxPool2D(2)(f)\n",
    "\t\tp = layers.Dropout(0.3)(p)\n",
    "\t\treturn f, p \n",
    "\t\n",
    "\tdef upsample_block(self,x, conv_features, n_filters):\n",
    "\t\t# upsample\n",
    "\t\tx = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "\t\t# concatenate\n",
    "\t\tx = layers.concatenate([x, conv_features])\n",
    "\t\t# dropout\n",
    "\t\tx = layers.Dropout(0.3)(x)\n",
    "\t\t# Conv2D twice with ReLU activation\n",
    "\t\tx = self.double_conv_block(x, n_filters)\n",
    "\t\t\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef build_model(self):\n",
    "\t\tinputs = layers.Input(shape=self.input_dimension)\n",
    "\t\t# 1 - downsample\n",
    "\t\tf1, p1 = self.downsample_block(inputs, 64)\n",
    "\t    # 2 - downsample\n",
    "\t\tf2, p2 = self.downsample_block(p1, 128)\n",
    "\t    # 3 - downsample\n",
    "\t\tf3, p3 = self.downsample_block(p2, 256)\n",
    "\t    # 4 - downsample\n",
    "\t\tf4, p4 = self.downsample_block(p3, 512)\n",
    "\t\t# 5 - bottleneck\n",
    "\t\tbottleneck = self.double_conv_block(p4, 1024)\n",
    "\t\t# decoder: expanding path - upsample\n",
    "\t\t# 6 - upsample\n",
    "\t\tu6 = self.upsample_block(bottleneck, f4, 512)\n",
    "\t    # 7 - upsample\n",
    "\t\tu7 = self.upsample_block(u6, f3, 256)\n",
    "\t    # 8 - upsample\n",
    "\t\tu8 = self.upsample_block(u7, f2, 128)\n",
    "\t    # 9 - upsample\n",
    "\t\tu9 = self.upsample_block(u8, f1, 64)\n",
    "\t    # outputs\n",
    "\t\toutputs = layers.Conv2D(3, 1, padding=\"same\", activation = \"sigmoid\")(u9)\n",
    "        # unet model with Keras Functional API\n",
    "\t\tunet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\t\treturn unet_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_image_samples():\n",
    "\tplt.figure(figsize=(10,10))\n",
    "\tfor i in range(25):\n",
    "\t\tplt.subplot(5,5,i+1)\n",
    "\t\tplt.xticks([])\n",
    "\t\tplt.yticks([])\n",
    "\t\tplt.grid(False)\n",
    "\t\tplt.imshow(train_images[i])\n",
    "\tplt.show()\n",
    "\n",
    "def plot_image_samples_with_noise():\n",
    "\tplt.title(\"Image with noise\")\n",
    "\tplt.subplot(2,1,1)\n",
    "\tplt.imshow(train_images[0])\n",
    "\tplt.subplot(2,1,2)\n",
    "\tplt.imshow(train_image_with_noise[0])\n",
    "\tplt.show()\n",
    "\n",
    "def plot_prediction(predct,epoch):\n",
    "\t#print(predct[0].shape)\n",
    "\tplt.title(\"Predicted image\")\n",
    "\tplt.title(\"Image with noise\")\n",
    "\tplt.subplot(1,4,1)\n",
    "\tplt.imshow(train_images[0])\n",
    "\tplt.subplot(1,4,2)\n",
    "\tplt.imshow(train_image_with_noise[0])\n",
    "\tplt.subplot(1,4,3)\n",
    "\tplt.imshow(predct[0])\n",
    "\tplt.subplot(1,4,4)\n",
    "\tplt.imshow(abs(train_image_with_noise[0]-predct[0]))\n",
    "\tplt.savefig(\"Epoch: {}\".format(epoch))\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "\t(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "\t# Normalize pixel values to be between 0 and 1\n",
    "\ttrain_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\treturn train_images,test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add noise\n",
    "def data_with_noise(noise_level):\n",
    "    uni_noise=np.zeros((32,32,3),dtype=np.uint8)\n",
    "    cv2.randu(uni_noise,0,255)\n",
    "    uni_noise=(uni_noise).astype(np.uint8)/255.0\n",
    "\n",
    "    train_images,test_images=load_dataset()\n",
    "\n",
    "    train_image_with_noise=train_images +uni_noise*noise_level\n",
    "    test_image_with_noise=test_images +uni_noise*noise_level\n",
    "    return train_image_with_noise, train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load model UNet\n",
    "Unet_model= UNet().build_model()\n",
    "#Unet.summary()\n",
    "Unet_model.compile(optimizer='adam', loss= tf.keras.losses.MeanAbsoluteError(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "for noise_level in range(0,0.05,1):\n",
    "    train_image_with_noise, train_images=data_with_noise(noise_level)\n",
    "    print(\"Noise level: {}\".format(noise_level))\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        for i in range(0, len(train_images), batch_size):\n",
    "            x_batch = train_image_with_noise[i:i+batch_size]\n",
    "            y_batch = train_images[i:i+batch_size]\n",
    "            \n",
    "            loss, accuracy = Unet_model.train_on_batch(x_batch, y_batch)\n",
    "            print(f\"Batch {i//batch_size + 1}: Loss = {loss:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "            \n",
    "        predicted_img = Unet_model.predict(np.expand_dims(train_images[0], axis=0))\n",
    "        plot_prediction(predicted_img,epoch)\n",
    "\n",
    "#Unet_model.save('./models/Unet_model.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
